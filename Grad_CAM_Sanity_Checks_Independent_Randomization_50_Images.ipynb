{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grad-CAM-Sanity-Checks-Independent-Randomization-50-Images.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42de130ba761417095a89797f9149dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_06122f29f6c94afba19b54ccef94ae5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f138b9b9ceb34f1ba390d01510e03d7f",
              "IPY_MODEL_f5d372c7d09a4b348c70db24c228c518"
            ]
          }
        },
        "06122f29f6c94afba19b54ccef94ae5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f138b9b9ceb34f1ba390d01510e03d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_853e516d85e64452b5e968336867d630",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bce07459c2e49918f46c01ed322062b"
          }
        },
        "f5d372c7d09a4b348c70db24c228c518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e97120194a264ffba7efab56dc06c854",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:14&lt;00:00, 41.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a9f6a70a67e4f4fbf6dfff022a4e78b"
          }
        },
        "853e516d85e64452b5e968336867d630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bce07459c2e49918f46c01ed322062b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e97120194a264ffba7efab56dc06c854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a9f6a70a67e4f4fbf6dfff022a4e78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlIpqVOgCbN1",
        "outputId": "53ab707c-768f-4956-98f5-54798527a3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "#Doing this because, sometimes we get an error 'module 'PIL.Image' has no attribute 'register_extensions' in Google Colab\n",
        "#uninstall the old one\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==4.1.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-7.0.0:\n",
            "  Successfully uninstalled Pillow-7.0.0\n",
            "Collecting Pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.7MB 4.3MB/s \n",
            "\u001b[?25hCollecting olefile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 29.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: olefile\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=03473cdf7126543e953dbb3439688f22a7e04bdc0b58604a0a57913944883914\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "Successfully built olefile\n",
            "\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: olefile, Pillow\n",
            "Successfully installed Pillow-4.1.1 olefile-0.46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2gWjRD1azqu",
        "outputId": "bcee1701-4b8c-433a-f61c-c34261d77eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/Shubhambindal2017/GRAD-CAM-with-Sanity-Checks.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GRAD-CAM-with-Sanity-Checks'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/19)\u001b[K\rremote: Counting objects:  10% (2/19)\u001b[K\rremote: Counting objects:  15% (3/19)\u001b[K\rremote: Counting objects:  21% (4/19)\u001b[K\rremote: Counting objects:  26% (5/19)\u001b[K\rremote: Counting objects:  31% (6/19)\u001b[K\rremote: Counting objects:  36% (7/19)\u001b[K\rremote: Counting objects:  42% (8/19)\u001b[K\rremote: Counting objects:  47% (9/19)\u001b[K\rremote: Counting objects:  52% (10/19)\u001b[K\rremote: Counting objects:  57% (11/19)\u001b[K\rremote: Counting objects:  63% (12/19)\u001b[K\rremote: Counting objects:  68% (13/19)\u001b[K\rremote: Counting objects:  73% (14/19)\u001b[K\rremote: Counting objects:  78% (15/19)\u001b[K\rremote: Counting objects:  84% (16/19)\u001b[K\rremote: Counting objects:  89% (17/19)\u001b[K\rremote: Counting objects:  94% (18/19)\u001b[K\rremote: Counting objects: 100% (19/19)\u001b[K\rremote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 19 (delta 6), reused 14 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAc7v5StIM3i"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "import skimage\n",
        "import torchvision\n",
        "from skimage import io\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage import transform\n",
        "import torch\n",
        "from matplotlib import cm\n",
        "import scipy\n",
        "from skimage.feature import hog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0V3uG-0DMuC"
      },
      "source": [
        "img_dir = '/content/drive/My Drive/Interpretability Research/50_Random_Images'\n",
        "images = os.listdir(img_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKjpKsiybxuR",
        "outputId": "8d45274c-a0e9-4a3a-e370-272b5874c273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/GRAD-CAM-with-Sanity-Checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GRAD-CAM-with-Sanity-Checks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzcUo0RRIgIB"
      },
      "source": [
        "from get_models import get_default_model, cascade_randomization, independent_randomization\n",
        "from prepare_model import prepare_model_for_gradcam\n",
        "from updated_utils import get_saliency, batch_overlay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lity9L_2JbyL"
      },
      "source": [
        "modelname = 'vgg19'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRpnRxOKLm-x"
      },
      "source": [
        "import pickle \n",
        "\n",
        "files = open(\"/content/drive/My Drive/Interpretability Research/synset_to_clsidx.pkl\", \"rb\")\n",
        "synset_to_clsidx = pickle.load(files)\n",
        "\n",
        "files = open(\"/content/drive/My Drive/Interpretability Research/clsidx_to_labels.pkl\", \"rb\")\n",
        "clsidx_to_labels = pickle.load(files)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqVa_iNIpLD7"
      },
      "source": [
        "## Categories of interest ##\n",
        "\n",
        "categories = []\n",
        "class_names = []\n",
        "\n",
        "for img in images:\n",
        "\n",
        "  synset = os.path.basename(img).split('_')[0]\n",
        "  class_name = clsidx_to_labels[synset_to_clsidx[synset]]\n",
        "  categories.append(synset_to_clsidx[synset])\n",
        "  class_names.append(class_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yirVi9NEDobe"
      },
      "source": [
        "model_imsize = 224,224\n",
        "\n",
        "vgg_mean = (0.485, 0.456, 0.406)\n",
        "vgg_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "model_mean,model_std = vgg_mean,vgg_std \n",
        "preprocess = torchvision.transforms.Compose([torchvision.transforms.Resize(model_imsize),\n",
        "                                    torchvision.transforms.ToTensor(),\n",
        "                                    torchvision.transforms.Normalize(mean = model_mean,std=model_std)\n",
        "                                    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwgm2vZ2Du2u",
        "outputId": "4e606776-d71b-42f7-f3a2-8fdca381ae7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "refs = []\n",
        "ims = []\n",
        "\n",
        "for img, class_of_interest in zip(images, categories):\n",
        "\n",
        "  im = io.imread(os.path.join(img_dir, img))\n",
        "\n",
        "  if len(im.shape) == 2:\n",
        "    im = np.stack((im,)*3, axis=-1)\n",
        "\n",
        "  print(im.shape)\n",
        "\n",
        "  ims.append(im)\n",
        "\n",
        "  im_pil = Image.fromarray(im)\n",
        "  ref = preprocess(im_pil).unsqueeze(0)\n",
        "  print(ref.shape)\n",
        "  ref = ref.cuda()\n",
        "\n",
        "  refs.append(ref)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(332, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(459, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(1200, 1600, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 463, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(189, 311, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 375, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(371, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(334, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(141, 160, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(300, 400, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 376, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(333, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 375, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(400, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 333, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(447, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(333, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(400, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 347, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 375, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(333, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(300, 247, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(345, 540, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(333, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(357, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(400, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(332, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(333, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 375, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 355, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 333, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(80, 80, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(371, 430, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(388, 520, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(400, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 400, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(165, 260, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(210, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 365, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 317, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(500, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n",
            "(375, 500, 3)\n",
            "torch.Size([1, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwlp-_ZNMGi"
      },
      "source": [
        "final_refs = None\n",
        "for ref in refs:\n",
        "\n",
        "  if final_refs == None:\n",
        "    final_refs = ref\n",
        "\n",
        "  else:\n",
        "    final_refs = torch.cat([final_refs,ref],0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S650QMjR9K8",
        "outputId": "185aeb98-19b2-4e3f-b2bf-b3731c5961ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "final_refs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asj1oPXJK9Uo",
        "outputId": "a36fb34b-d208-4aed-b3a6-82821a18c272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "42de130ba761417095a89797f9149dcf",
            "06122f29f6c94afba19b54ccef94ae5e",
            "f138b9b9ceb34f1ba390d01510e03d7f",
            "f5d372c7d09a4b348c70db24c228c518",
            "853e516d85e64452b5e968336867d630",
            "5bce07459c2e49918f46c01ed322062b",
            "e97120194a264ffba7efab56dc06c854",
            "6a9f6a70a67e4f4fbf6dfff022a4e78b"
          ]
        }
      },
      "source": [
        "\n",
        "independent_random_output_binaries = {}\n",
        "\n",
        "for i in range(1, 17):\n",
        "\n",
        "  print(f'i ---> {i}')\n",
        "\n",
        "  independent_random_output_binaries[i] = []\n",
        "  \n",
        "  model, model_imsize, preprocess = independent_randomization(modelname = modelname, layer = i)\n",
        "\n",
        "  last_spatial_layer,hooked_last_spatial,bwdhooked_last_spatial = prepare_model_for_gradcam(modelname,model)\n",
        "\n",
        "  L_c_nps, heat_maps, ref_scores = get_saliency(model, final_refs , categories, model_imsize, last_spatial_layer)\n",
        "\n",
        "  #saliency_overlayed, pil_heat_map_jet = batch_overlay(heat_maps, ims, model_imsize)\n",
        "\n",
        "  for heat_map in heat_maps:\n",
        "\n",
        "    #independent_random_output_binary = np.mean(np.asarray(heat_map), axis=2).astype('uint8')\n",
        "\n",
        "    #independent_random_output_binaries[i].append(independent_random_output_binary)\n",
        "\n",
        "    independent_random_output_binaries[i].append(heat_map)\n",
        "\n",
        "  del model\n",
        "  torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i ---> 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42de130ba761417095a89797f9149dcf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "i ---> 2\n",
            "i ---> 3\n",
            "i ---> 4\n",
            "i ---> 5\n",
            "i ---> 6\n",
            "i ---> 7\n",
            "i ---> 8\n",
            "i ---> 9\n",
            "i ---> 10\n",
            "i ---> 11\n",
            "i ---> 12\n",
            "i ---> 13\n",
            "i ---> 14\n",
            "i ---> 15\n",
            "i ---> 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOsx978hiWJ-",
        "outputId": "12299b1d-10cb-4aa5-df43-0a1a96d8c88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "independent_random_output_binaries.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-FHNJX_iZdr",
        "outputId": "94a0af8c-3623-4615-a4a5-704b33ca9b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(independent_random_output_binaries[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjbSccBbidOM",
        "outputId": "9c1542f8-3863-4e37-c0c6-f92ed0fc0a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "independent_random_output_binaries[1][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4G1ZSdGdcjH"
      },
      "source": [
        "import pickle\n",
        "\n",
        "files = open(\"/content/drive/My Drive/Interpretability Research/Salieny_maps/independent_random_output_binaries.pkl\", \"wb\")\n",
        "pickle.dump(independent_random_output_binaries , files)\n",
        "files.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP45A-yaeW77",
        "outputId": "7f8d5176-c87a-45d2-8452-52a821241a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug  8 15:06:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    37W / 250W |   8131MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GNbT_irm6j5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}